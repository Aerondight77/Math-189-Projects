---
title: 'Homework 4: Hypothesis Testing'
author: "|Daria Barbour-Brown\n|Bailey Ho\n|Warren Kennedy\n"
date: April 28, 2022
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
**All group members contributed equally to this assignment.**

# Conceptual Question

## Question 1

Type I errors occur when the null hypothesis is rejected, even though it is true, resulting in false positive findings. Type II errors occur when the null hypothesis is not rejected, even though it is false, resulting in false negative findings. The severity of each error depends on the context of the situation, with type I errors being more severe in situations where false positives have significant consequences, such as medical diagnoses or legal judgments. For example, if a medical test incorrectly diagnoses a person with a disease, they may receive unnecessary treatments that can be harmful to their health. Type II errors are more severe in situations where false negatives have significant consequences, such as failing to detect a serious illness or safety hazard. For example, a faulty fire detector that fails to detect a fire can have serious consequences in terms of property damage and loss of life. It is important to carefully consider the costs and benefits of each type of error in a particular situation.

# Application Question

## Question 2

The USDA Womens Health Survey data set contains five types of womens nutrient intakes which were measured from a random sample of 737 women aged 25-50 years in United States.

### Part A

```{r}
nutrients <- read.csv("~/GitHub/Math-189-Projects/Homework 4/nutrients.csv")

sample.mean = sapply(nutrients, mean)
sample.sd = sapply(nutrients, sd)

```

### Part B 

```{r}

calc.t = t.test( nutrients[,1], alternative= "two.sided", mu = 1000, conf.level = 0.95)
iron.t = t.test( nutrients[,2], alternative= "two.sided", mu = 15, conf.level = 0.95)
prot.t = t.test( nutrients[,3], alternative= "two.sided", mu = 60, conf.level = 0.95)
vitA.t = t.test( nutrients[,4], alternative= "two.sided", mu = 800, conf.level = 0.95)
vitC.t = t.test( nutrients[,5], alternative= "two.sided", mu = 75, conf.level = 0.95)

```

### Part C

```{r}
pval=c(calc.t$p.value,iron.t$p.value,prot.t$p.value,vitA.t$p.value,vitC.t$p.value)
mu= c(calc.t$estimate,iron.t$estimate,prot.t$estimate,vitA.t$estimate,vitC.t$estimate)
pval= t(as.data.frame(pval))
mu = t(as.data.frame(mu))
Findings= rbind(pval,mu)
rownames(Findings)= (c("P-value","Mean"))
colnames(Findings) = c("Calcium", "Iron", "Protein", "Vitamin A", "Vitamin C")

knitr::kable(Findings)
```

Significant results were obtained from the hypothesis test examining the levels of Calcium, Iron, and Protein compared to their recommended intake levels, as evidenced by the small p-values. This indicates that the null hypothesis, which states that the sample means are equal to the recommended levels, can be rejected. Specifically, the sample mean for Calcium was found to be 624, which falls below the recommended level of 1000. While the sample mean values for Iron and Protein were also lower than recommended, the difference was not as pronounced as it was for Calcium. As data scientists, we strongly recommend that Women increase their intake of these three crucial nutrients, with a particular emphasis on Calcium.

Conversely, the hypothesis test conducted on Vitamin A and Vitamin C yielded larger p-values, indicating that the sample mean values are likely to have come from a distribution with sample means that are not significantly different from the values being tested. Therefore, we cannot reject the null hypothesis, and do not recommend any changes to the intake levels for Vitamin A and Vitamin C.

## Question 3

```{r}
multiple <- read.table("~/GitHub/Math-189-Projects/Homework 4/multiple.txt", quote="\"", comment.char="")
```

### Part A

```{r}
m = 50
pv <- numeric(m)
for(j in 1:m){
  t_test <- t.test(multiple[,j], mu=0,conf.level = 0.9)
  pv[j] <- t_test$p.value
}
```

### Part B

```{r}
sum(pv[11:50] < 0.1) # false positives
sum(pv[1:10] > 0.1) # false negatives
sum(pv[11:50] < 0.1)/sum(pv < 0.1) # false discovery proportion
```

### Part C

```{r}
bonf <- p.adjust(pv,method="bonferroni")
sum(bonf[11:50] < 0.1) # false positives
sum(bonf[1:10] > 0.1) # false negatives
sum(bonf[11:50] < 0.1)/sum(bonf < 0.1) # false discovery proportion
```

### Part D

```{r}
bh <- p.adjust(pv,method="BH")
sum(bh[11:50] < 0.1) # false positives
sum(bh[1:10] > 0.1) # false negatives
sum(bh[11:50] < 0.1)/sum(bh < 0.1) # false discovery proportion
```

In Part B of our study, we conducted multiple testing using the naive approach. The naive approach to multiple testing is a simple method of performing statistical tests on multiple hypotheses without adjusting for the increased probability of making a type I error due to the number of tests performed. 
In the naive approach, each test is conducted at the same significance level regardless of the number of tests performed. This can lead to an increased probability of false positives, especially when a large number of tests are conducted.  Our test using this approach yielded four false positives and no false negatives, which resulted in a false discovery proportion of 28 percent. 

In Part C, we implemented the Bonferroni method , a conservative method that controls the family-wise error rate, which is the probability of making at least one Type I error among all the tests conducted. It does this by adjusting the significance level of each test by dividing it by the number of tests performed. Using the Bonferroni approach, we observed a notable reduction in false positives without any impact on false negatives. Remarkably, we achieved zero false positives and zero false negatives, thereby bringing down the proportion of false discoveries to zero. 

In Part D, we applied the BH procedure. The BH procedure is a more liberal method that controls the false discovery rate, which is the proportion of false positive results among all significant results. It achieves this by adjusting the p-values of each test based on the number of tests conducted and the expected proportion of false positives. The BH procedure is generally considered to be more powerful than the Bonferroni correction, especially when there are many tests and a large proportion of them are expected to be significant.
Remarkably, we achieved zero false positives and zero false negatives, which is analogous with the findings yielded using the Bonferroni method.
